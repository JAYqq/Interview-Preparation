## Why

为什么要有网络协议？网络传输的本质是socket之间的字节流传输，但是怎么样能传输更多的信息，比如数据大小、编码等，所以需要网络协议对socket进行封装

## HTTP

1. 基本概念

   超文本传输协议，是一个明文传输的无状态的协议，无状态也就是无法通过HTTP来维护用户的状态，每次请求都相互独立（所以这里经常会使用cookie或者session来维护状态）。

2. **GET和POST的区别**

   - 从用途上讲，一般GET用户获取资源，POST是传输实体主体
   - GET携带参数是放在URL中的，而POST是放在报文主体中传输的，但是这并不代表POST的安全性更高。
   - **幂等性**上来讲，GET方法是幂等的，它用于获取资源，所以执行一次和多次结果都是一样的。而POST不是幂等的，因为它会对服务端的数据做出修改而产生变化。
   - **缓存**上来讲，GET方法由于是获取资源，所以可以被缓存，而POST请求会和数据库打交道，所以不能缓存

3. **缓存**

   包括代理服务器缓存和客户端缓存

   首先通过头部字段Cache-Control来控制缓存，主要的参数是not-store(对请求或相应都不缓存)、no-cache(强制确认缓存有效性，也就是当前的资源是否是最新的)、private、public

   **缓存验证**，一般有两种方式：

   - 通过ETAG字段来表示资源的唯一标识，因为URL无法表示唯一资源，可以将ETAG的值放到If-None-Match首部字段，请求到了服务器，就可以判断一下最新资源的ETAG值是否相同，如果一致就返回304，这样就可以直接用缓存的资源。
   - 用Last-Modified，判断资源是否被修改过，但是由于这个值只精确到1秒，所以一般用作ETAG的备选方案

4. 几个重要的状态码

   4XX 客户端错误

   - 400 Bad Request ：请求报文中存在语法错误。
   - 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
   - 403 Forbidden ：请求被拒绝。
   - 404 Not Found

   5XX 服务器错误

   - 500 Internal Server Error ：服务器正在执行请求时发生错误。
   - 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。
   
   

## HTTPS

1. HTTPS链接过程

   HTTPS是通过对称和非对称加密技术共同实现的加密传输协议

   过程是：

   - 服务端向第三方机构申请证书，数字证书=网站信息（未加密）+数字签名

     第三方将网站信息（信息中包含服务端的公钥）加密后(数字摘要算法)，然后第三方用自己的私钥加密证书中已经加密过的网站信息。最后给到服务端

   - 客户端向服务端申请证书。

   - 客户端拿到证书以后用向第三方申请的公钥（很多浏览器已经在本地储存了常见第三方的公钥）解密数字签名，验证合法性：合法性就是客户端拿到证书以后第三方公钥解密出加密过的网站信息，然后用同样的数字加密算法重新加密网站信息，查看两者是否相等。

   - 如果合格，客户端生成秘钥，然后用服务端的公钥加密后发送给服务端

   - 服务端收到后用自己的秘钥非对称解密，得到客户端秘钥，然后客户端用秘钥进行数据加密传输。

2. http和https的区别

   - http是一种明文传输协议，而https是在http的基础上进行了加密

3. https的缺陷

   - 因为需要进行加密解密等过程，因此速度会更慢；
   - 需要支付证书授权的高额费用。

## TCP

1. TCP 协议如何保证可靠传输

   - **校验和**： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

   - **流量控制**：  只关心发送方和接收方的窗口大小，而不关心链路中的具体情况。

     TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据（这个叫做窗口大小，放在TCP头部窗口字段）。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。（这里还有一个ACK和窗口大小的合并，这样不用分成两个包来传输了，提高了效率）。并不是每次发送一个发送窗口大小的数据，而是发送MSS，所以这个MSS可能会比发送窗口小

   - **拥塞控制**： 考虑到链路中的阻塞情况，主要就是维护拥塞窗口

     **整理一下下面，宏观上看，拥塞控制主要依靠慢启动、拥塞避免、快重传和快恢复，但是依旧面临丢包问题，那么在拥塞避免算法加一递增到丢包了，如何检测出丢包，并且丢包就涉及到重传机制，主要依靠超时重传和快重传**

     涉及到整个网络的拥塞情况，并作为一个**拥塞窗口**(cwnd)的状态变量，放入TCP头部中实现拥塞控制。发送窗口大小=min(接收方窗口大小，拥塞窗口大小)，主要算法有：

     - 慢开始

       较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。

       ![img](https://img-blog.csdn.net/20180506145526553?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQ1OTA3NTc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

     - 拥塞避免

       拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1.

     - 快重传（FRR）与超时重传

       **都是用来确认丢包的**

       有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段（**主要结合快恢复**）
       
       超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。（**主要用在慢开始中进入拥塞避免后判断超时**）
       
       **快重传解决了超时重传的限定time问题，它不需要等待超时时间。另外快重传在**
       
       ![img](https://upload-images.jianshu.io/upload_images/3256507-d97c8b1425c23a6e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1174/format/webp)
       
     - 快重传和快恢复

       快恢复相对于拥塞避免的好处就是抛弃了慢启动，在通过快重传确认丢包以后直接将拥塞窗口变为一半，而不是从1开始

       ![img](https://img-blog.csdn.net/20180506145535862?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTQ1OTA3NTc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

   - **停止等待协议**: 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就- 停止发送，等待对方确认。在收到确认后再发下一个分组。停止等待协议可以理解成滑动窗口协议的低等版，也就是当接受和发送窗口都为1的时候的模式。因为滑动窗口一直全力发送，到后面一定会出现发送窗口为1接受也是为1,。

2. 滑动窗口

   滑动窗口是在吞吐量和发送数据的有序性上面做了一个兼并，也就是**不需要每发送一个包就等待它的ACK**，而是可以连续发送多个包，只需要收到最后一个序号的确认报就表示前面的包都收到了。**但是如果前面有包没有收到，那么滑动窗口发送完一个窗口大小后就会停止等待，直到超时重传**，收到了这个包的确认报之后才会往后滑动，这样保证了窗口之前的数据包都是已经被成功发送的数据包。

   另外发送窗口的大小也需要根据具体情况做出改变，发送窗口大小=min(接收方窗口大小，拥塞窗口大小)

3. **网络上的传输是没有连接的，包括TCP也是一样的**。而TCP所谓的“连接”，其实只不过是在通讯的双方维护一个“连接状态”，让它看上去好像有连接一样。所以，TCP的状态变换是非常重要的。

4. TCP**三次握手**

   - 为什么需要三次握手？

     第一次客户端请求链接重传对服务端影响：

     客户端发送的连接请求如果在网络中**滞留**，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

     对于第二次服务端返回的请求失效：

     如果服务器返回的SYN+ACK的包在网络中丢失了，那么就会导致服务端已经处于Establish的状态，准备传输数据，但是其实客户端还没有连接成功，必须重传连接包，然后服务端又会重新简历新的连接，这样就导致了前一个连接端口一直开着直到**保活计时器**结束。

   - **关于建连接时SYN超时**。试想一下，如果server端接到了clien发的SYN后回了SYN-ACK后client掉线了，server端没有收到client回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP才会把断开这个连接。

   - 如果已经建立了连接，但是客户端突然出现故障了怎么办？

     TCP还设有一个**保活计时器**，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

   - **SYN队列和Accept队列**

     处于“LISTENING”状态的TCP socket，有以上两个独立的队列。**SYN队列**储存收到的SYN连接，这个队列的任务就是进行SYN和ACK确认然后判断重传（这里的重传也就是上面的63秒）发送完SYN+ACK之后，SYN队列等待从客户端发出的ACK包（也即三次握手的最后一个包）。当收到ACK包时，首先找到对应的SYN队列，再在对应的SYN队列中检查相关的数据看是否匹配，如果匹配，内核将该连接相关的数据从SYN队列中移除，创建一个完整的连接（对应内核代码的结构体：[struct inet_sock](https://elixir.free-electrons.com/linux/v4.14.12/source/include/net/inet_sock.h#L183)），并将这个连接加入Accept队列。

     **Accept队列**中存放的是已建立好的连接，也即等待被上层应用程序取走的连接。当进程调用accept()，这个socket从队列中取出，传递给上层应用程序。

   - **SYN Flood攻击**

     就是利用了这个63秒，攻击者在客户端发送了TCP的SYN包之后就马上下线，这样就会导致服务器不得不重传等待63秒，如果这个过程被重复，那么SYN队列就会满掉，导致其他的链接无法进行。

     **解决** **SYN cookies 算法**

     我们知道，`TCP`连接建立时，双方的起始报文序号是可以**任意**的。`SYN cookies`利用这一点，按照以下规则构造初始序列号：

     - 设`t`为一个缓慢增长的时间戳(典型实现是每64s递增一次)
     - 设`m`为客户端发送的`SYN`报文中的`MSS`选项值
     - 设`s`是连接的元组信息(源IP,目的IP,源端口，目的端口)和`t`经过密码学运算后的`Hash`值，即`s = hash(sip,dip,sport,dport,t)`，`s`的结果取低 **24** 位

     总结来说，三次握手的主要目的就是交换彼此的初始序号，系统需要对SYN队列中的所有连接进行资源分配，也就是分配空间去储存此次请求的信息（四元组，MSS，时间戳），但是由于现在SYN队列满了，所以我们就只能在不分配资源的情况下获取这些信息，因为已经没有队列去记忆初始序号了。SYN cookie方法 **通过构造一个初始序号，这个序号采用了哈希算法，然后制造一个SYN+ACK的包发送给客户端，根据TCP规范，客户端必须返回一个ACK确认包，并且之中有确认序号ack（n+1），服务端接收到这个确认包之后，就可以根据ack-1得出一开始的序号值**，这样就完成了一次连接，可以进入到Accept队列中。

5. TCP四次挥手

   - 为什么需要四次挥手

     其实四次挥手和三次握手最主要的不同在于第二次连接，握手的时候服务端发送的SYN+ACK既包含了请求连接的意向，也包含了对之前客户端发起连接请求的确认，而挥手的时候，FIN和ACK是分两个包发出去的，这是因为服务端这边数据可能还没有完全发送完，所以需要先返回ACK让客户端进入FIN_WAIT2状态。
     
   - **TIME_WAIT**
   
     主要的两个作用：
   
     1. 为了防止最后的ACK没有到达被断开的一方，在timewait时间内可以重传最后的ack
     2. 一个数据包在网络中的生命周期是MSL，而timewait的长度是两个MSL这样就可以让所有本次连接的包都被耗死在网络中，而不会去影响下一次相同的连接。
   
6. 慢启动和拥塞避免算法

   **拥塞窗口是发送方控制流量，滑动窗口是接收方控制流量**

   而发送窗口是取两者最小值

7. timewait出现过多拥塞怎么解决？

   https://zhuanlan.zhihu.com/p/40013724（必看）

   1. 打开SYN-cookie，来应由于过多的timewait占用资源而让新的连接连握手的完成不了。

   2. **net.ipv4.tcp_tw_reuse = 1**  定义了TCP的新选项，一个四个字节的时间戳，时间戳中一个是发送方发送时的时间戳，另一个是接收方接受的时间戳。可以让socket可以重复被新的连接使用，这个只适用于发送方，并且timewait的时间戳和新连接的时间戳至少隔了一秒。对于接受方来说，如果如果由于没有收到ACK重发FIN后接收到正确的ACK，那么就正常挥手，但是如果客户端这个连接已经被重用，那么接受方就会接收到一个RST包，这会让服务端脱离LAST_ACK状态。由于使用了时间戳，所以在timewait时间内的重复的数据包会因为过期导致失效。这个主要的目的是主动方如果出现大量timewait，就可以进行连接复用。所以配置在被动方没有什么用

   3. 如果是内网环境，可以开启**net.ipv4.tcp_tw_recycle**，这个主要在被动方打开，依赖于timestamp，是直接毁掉这个连接，默认时间时一个RTO（数据包重传时间）而不是跟reuse一样去复用。如果这个配置在NET环境下，也就是以多台电脑和负载均衡服务器这个环境下的负载均衡器上，由于每一台外设电脑都是和负载均衡器一个端口进行五元祖（源IP+源端口，目标IP+目标端口，+协议）连接时，由于每台电脑的内核时间戳不一致，所以导致一个RTO时间内只能有一个连接成功，其他连接的数据包发过来可能会因为时间戳过期直接抛弃。

      内核会记住**客户端上次发来数据包的时间戳**, 如果发来的数据包时间戳小于内核记录的最后发来的数据包时间戳, 那么将会丢弃此数据包

   4. 修改timewait的值，下下策。

   5. 增加可用端口的数量。

   

### Cookie和Session区别

1. cookie可以用来做会话跟踪，也可以用来储存其他的信息。session就是用来会话跟踪的。

2. cookie储存在客户端，每次请求时需要客户端携带cookie来维持会话状态。session保存在服务端，以session_id为索引的数据结构，所以当用户量比较大的时候会占用大量内存影响服务器的性能。session一般依赖于cookie实现，但是也可以通过URL重写来实现。

3. cookie分为会话型cookie和持久性cookie。cookie的安全问题主要体现在如果一个网站使用cookie作为用户唯一标识，那么攻击者可以盗用cookie来伪装用户。可以设置HTTPONLY禁止掉JS操作cookie，或者设置cookie的secure属性，这样只能用HTTPS传输cookie。也可以在cookie中设置一些像UserAgent来提高安全性。

   session的安全问题主要在于攻击者可以用session_id来伪装用户。

4. cookie还有一个很重要的问题就是大多移动设备不支持

5. cookie存在跨域问题，因为cookie是和域名绑定的，所以无法使用这个网站的cookie去访问另一个网站，如果是二级域名的话，可以设置cookie的domain参数。Session存在共享session问题，因为sessionID保存在服务器上，如果应用做了负载均衡，那么当这个客户端的请求被转发到另一台没有储存session的服务器上，就会无法识别，主要策略有：

   - 固定每个用户到指定的服务器。但是这样导致了单点问题，如果这个服务器宕机了，那么用户就无法访问。
   - session复制。但是也无法解决session耗费资源的问题，并且数百台服务器之间的session同步问题也很头疼。
   - session集中处理，放在第三方服务器中。这样虽然避免了负载均衡后的服务器的session消耗，但是如果这台第三方服务器宕机了，那就凉了
   - Token

### IO多路复用的三种模型

https://blog.csdn.net/Eunice_fan1207/article/details/99674021

https://blog.csdn.net/shenya1314/article/details/73691088



**数据传输过程**

1. 网卡收到了数据以后，会触发中断，向CPU发送中断信号，然后网卡通过中断程序去处理数据（主要是将网络数据放到创建的socket对象的接收缓冲区，重新唤醒进程，将进程加入工作队列中）

   操作系统如何知道数据应该放哪个socket中？

   答：由于数据包包含了ip和端口，而一个socket也对应一个端口，所以系统可以通过端口找到对应的socket

2. 如何同时监听多个socket

   **select**

   将一个进程加入到每个socket的等待列表中，如果有一个socket接收到了数据，那么就会使得这个进程从所有socket的等待列表中去掉，唤醒进程，这个进程知道了这么多socket中有一个接收到了数据，那么就遍历一遍socket列表。以上是调用select的时候没有任何socket有数据的情况，而其实调用select的时候，内核会遍历一遍socket列表，如果有一个以上的socket接收区有数据，那么直接返回，不会阻塞，这也是为什么select会返回大于1

   **缺点**

   - 每次调用select都要将进程加入到所有socket的等待列表，每一次唤醒还要从每个中移除。这里涉及了两次遍历，而且还需要将socket数组传给内核，所以规定了select的最大监听数量默认值是**1024**个
   - 进程被唤醒以后还需要进行一次遍历查看哪些socket接收到了数据
   - select需要从内核中复制大量的fd有关数据结构，这里就会有不小的时间开销
   - select是水平触发模式，所以当一个事件没有对socket完成一个完整的IO操作，select也会去读取数据

   **poll**

   poll相比于select来说是使用链表保存文件描述符，所以摆脱了1024的限制。

   **epoll**

   **epoll是一种I/O事件通知机制，是linux 内核实现IO多路复用的一个实现。**

   https://zhuanlan.zhihu.com/p/64746509

   select低效的原因是将维护等待队列和阻塞进程合二为一，epoll做的就是将这两步分开，先用epoll_ctl维护等待队列（**是一个链表**），再调用epoll_wait阻塞进程。**空间换时间**

   最大可监听的数量可以查看：**cat /proc/sys/fs/file-max**

   **流程**

   1. 当某个进程调用**epoll_create**方法时，内核会在cache中创建一个eventpoll对象，这是一个结构体

      ```c
      
      struct eventpoll{
          ....
          /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/
          struct rb_root  rbr;
          /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/
          struct list_head rdlist;
          ....
      }
      ```

      主要储存了就绪队列和红黑树。

      红黑树和双向链表的节点类型：

      ```c
      
      struct epitem{
          struct rb_node  rbn;//红黑树节点
          struct list_head    rdllink;//双向链表节点
          struct epoll_filefd  ffd;  //事件句柄信息
          struct eventpoll *ep;    //指向其所属的eventpoll对象
          struct epoll_event event; //期待发生的事件类型
      }
      ```

      

   2. 创建epoll对象后，可以用**epoll_ctl**添加或删除所要监听的socket，将用户态的event拷贝到内核态，也就是插入红黑树。

      具体实现是：https://blog.csdn.net/Mr_H9527/article/details/99745659

      首先要删除或者添加socket文件描述符的是调用epoll_ctl函数，该函数底层是调用了sys_epoll_ctl函数，这个函数接受的参数：

      ```c++
      sys_epoll_ctl(int epfd, int op, int fd, struct epoll_event __user *event)
      ```

      op代表操作类型是删除还是修改还是插入；fd是文件描述符。

      像插入操作的的过程如下：

      - epoll底层调用了ep_insert方法去插入，而这个方法是调用了ep_rbtree_insert方法去插入。
      - 这个方法首先用了个while循环查找到可以插入的位置
      - 然后进行插入，最后调用维护红黑树平衡的方法。
      - 然后**向内核注册回调函数**，如果有中断触发，那么就调用这个中断服务程序，向就绪链表插入fd，唤醒wait的进程

   3. 当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用，这个就绪列表中储存的是接收到数据的socket。

   4. 当进程执行到epoll_wait之后，系统会将这个进程放到eventpoll的等待队列中阻塞进程。

      ```c
      int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout);
      ```

      在epoll_wait主要是调用了ep_poll，在ep_poll里直接判断就绪链表有无数据，有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。当有数据时，还需要将内核就绪事件拷贝到传入参数的events中的用户空间，就绪链表中的数据一旦拷贝就没有了，所以这里要区分LT和ET，如果是LT有可能会将后续的重新放入就绪链表。

      events: 用来记录被触发的events，数组，其大小应该和maxevents一致，events和maxevents两个参数描述一个由用户分配的struct epoll event数组

      

   5. socket接受数据后一边修改就绪列表，一边也会唤醒eventpoll里面的阻塞进程，由于这些被唤醒的进程可以通过就绪列表知道哪些socket收到数据了，所以不需要遍历列表。

   **水平触发和边缘触发**

   https://zhuanlan.zhihu.com/p/107995399

   - 水平触发就是只要socket中有数据，就会触发返回数据给epoll_wait()阻塞的进程
   - 边缘触发是等到socket有数据写入的事件发生，才会去触发返回数据给阻塞的进程

   **epoll的优势**

   - 相比与select，没有fd限制，可监听大量的socket
   - 不会随着FD数量的增加导致效率线性下降。如果监听的所有fd中只有部分是很活跃的，那么select和poll必须每次去循环所有fd，而epoll只储存有数据接受的socket，而不是所有的fd
   - 有两种触发模式，水平触发和边缘触发，像边缘触发只有socket缓冲区中新接受了数据才会触发epollwait，可以有效减少触发的次数，提高效率。
- 综上，当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。
   
**epoll的缺点**
   
   epoll将等待队列和就绪队列维护在内核，所以每次添加文件描述符都需要进行一个系统调用，系统调用的开销比较大，对于大量的短链接存在可能就会比较低效。

   **数据结构**

   1. 就绪列表储存socket的引用，所以需要是一个**能快速删除**和插入的数据结构。epoll采用了双向链表的数据结构。
2. 内核cache在epoll_create时创建红黑树，储存了监听的socket。
   
   **小问题**
   
1. epoll读到一半又有新事件来了怎么办？
   
   避免在主进程epoll再次监听到同一个可读事件，可以把对应的描述符设置为**EPOLL_ONESHOT**，效果是监听到一次事件后就将对应的描述符从监听集合中移除，也就不会再被追踪到。读完之后可以再把对应的描述符重新手动加上。
      
2. **为什么边缘触发一定要配合非阻塞IO**？
   
      因为在ET模式下，如果由于缓冲区没有数据阻塞在read()上的时候，系统又不能脱离read()去读取其他的socket数据，就会很大的影响效率。
   
   **面试总结**
   
   Linux epoll机制是通过红黑树和双向链表实现的。 首先通过epoll_create()系统调用在内核中创建一个eventpoll类型的句柄，其中包括红黑树根节点和双向链表头节点。然后通过epoll_ctl()系统调用，向epoll对象的红黑树结构中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败，并向内核注册回调函数。最后通过epoll_wait()系统调用判断双向链表是否为空，如果为空则阻塞。当文件描述符状态改变，fd上的回调函数被调用，该函数将fd加入到双向链表中，此时epoll_wait函数被唤醒，返回就绪好的事件。

### Socket

https://zhuanlan.zhihu.com/p/109826876

socket是应用层和传输层之间的一个抽象层，对TCP等传输层协议进行封装

linux中socket是文件的形式，而windows中是网络连接，而不是文件的形式

socket属于传输层，解决的事如何可靠传输的问题，http是应用层，解决的是如何封装数据包的问题。

## IP



## DNS

dns就是域名解析服务器，解析的流程一般如下：

1. 首先查看本地缓存，hosts文件中有些会定义域名和IP的对应

2. 本地没有缓存就去本地域名服务器，这个服务器设置是在/etc/resolv.conf中指定的，里面的nameserver按照顺序下来解析

3. 如果前两者都没有，那么就需要去进行递归查询或者迭代查询：以www.baidu.com 为例

   **递归查询**

   - 本地域名服务器先去询问根域名服务器（.root）
   - 如果没有找到，根域名服务器就去询问顶级域名服务器（.com）
   - 如果没有找到，顶级服务器就绪询问二级域名服务器（.baidu）
   - 如果还没有找到，就再往下递归寻找（.www）
   - 找到以后就将解析到的信息回溯给上一级服务器，直到根域名服务器反馈给本地然后返回给客户端

   **迭代查询**

   - 客户端先去问本地服务器
   - 没有的话客户端再去问根域名服务器
   - 再没有就再去问顶级服务器
   - 就这样，问到了以后直接返回给客户端，而不是往上回溯


## NAT

NAT是网络地址转换。因为如果每一台机器都分配公网ip，那么就很浪费ip地址。在局域网中，比如公司，一般就是可以在内部分配私有IP，这些ip是无法直接连接广域网的，无法上网，所以至少需要有一台具有公网IP的机器，去代替这些机器访问互联网，这就涉及到网络地址转换。主要分为：

- Basic NAT

  一对一的地址转换，也就是一个局域网中的每个机器固定会通过某个IP去访问互联网，并且一个公网IP不能不同被使用

  在实际中不常用，因为其实没有很好的解决IP地址紧缺的问题

- NAPT

  多对一，也就是多个机器能同时借助一个公网IP去访问互联网。这里其实用到了端口，也就是IP+PORT实现对同一个IP的并行使用

上面是主要的两种方式，其他还有延伸开来基于此：

- 静态NAT/NAPT

  静态NAT就是单单一对一的IP固定

  静态NAPT就是IP+端口的固定

- DNS mapping

  私网用户希望通过域名访问位于同一私网的内部服务器，而 DNS 服务器却位于公网，这样就可以使用dns mapping，nat服务器直接可以通过域名+公网IP+内部主机私有IP来解析

## RPC

RPC是一种远程通信协议，通常用在分布式系统之间解决系统之间的通信问题。

其实http也可以解决通信问题，但是需要开发者显示地去发起http请求，所以RPC就可以在开发者层面屏蔽显示的请求，而是像调用一个函数一样，这个屏蔽工作就是利用代理模式，这个代理模式内部就是通过http客户端实现（比如阿里的Dubbo）。

### **RPC要解决的两个问题：**

**1. 解决分布式系统中，服务之间的调用问题。**

**2. 远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。**

### 优势

1. 在接口非常多的情况下，使用http就会导致每次需要三次握手，而RPC是长连接，减少网络的开销。
2. 解耦服务，使用了动态代理模式

