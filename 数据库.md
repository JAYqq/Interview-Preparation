## 数据库

1. 数据库的异常情况

   1. 脏读(Dirty Read)

      当一个事务读取另一个事务尚未提交的修改时，产生脏读。

      同一事务内不是脏读。 一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交。这是相当危险的，因为很可能所有的操作都被回滚，也就是说读取出的数据其实是错误的。

      

   2. 不可重复读(Nonrepeatable Read) 一个事务对同一行数据重复读取两次，但是却得到了不同的结果。同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生非重复读。

      

   3. 幻像读(Phantom Reads)**多出来一个东西** 事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有**另外一个事务插入数据造成的**。

      当对某行执行插入或删除操作，而该行属于某个事务正在读取的行的范围时，会发生幻像读问题。

   4. 丢失修改(Lost Update)

      第一类：当两个事务更新相同的数据源，如果第一个事务被提交，第二个却被撤销，那么连同第一个事务做的更新也被撤销。

      第二类：有两个并发事务同时读取同一行数据，然后其中一个对它进行修改提交，而另一个也进行了修改提交。这就会造成第一次写操作失效。

2. 数据库的隔离级别

   1. 未提交读(Read Uncommitted)**出现脏读**

      直译就是"读未提交"，意思就是即使一个更新语句没有提交，但是别的事务可以读到这个改变。

      Read Uncommitted允许脏读。

      **公司发工资了，领导把5000元打到singo的账号上，但是该事务并未提交，而singo正好去查看账户，发现工资已经到账，是5000元整，非常高 兴。可是不幸的是，领导发现发给singo的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后singo实际的工资只有 2000元，singo空欢喜一场。**

   2. 已提交读(Read Committed)**解决脏读，出现不可重复读**

      直译就是"读提交"，意思就是语句提交以后，即执行了 Commit 以后别的事务就能读到这个改变，只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别。

      Read Commited 不允许脏读，但会出现非重复读。

      **singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在 singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，为 何……**

      **出现上述情况，即我们所说的不可重复读 ，两个并发的事务，“事务A：singo消费”、“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。**

      **当隔离级别设置为Read committed 时，避免了脏读，但是可能会造成不可重复读。**

   3. 可重复读(Repeatable Read)：**解决不可重复读，出现幻读**

      **当singo拿着工资卡去消费时，一旦系统开始读取工资卡信息（即事务开始），singo的老婆就不可能对该记录进行修改，也就是singo的老婆不能在此时转账。**

      直译就是"可以重复读"，这是说在同一个事务里面先后执行同一个查询语句的时候，得到的结果是一样的。

      Repeatable Read 不允许脏读，不允许非重复读，但是会出现幻象读。

   4. 串行读(Serializable)

      直译就是"序列化"，意思是说这个事务执行的时候不允许别的事务并发执行。完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。

      Serializable 不允许不一致现象的出现。

3. mysql的默认隔离级别是 **可重复读**，**binlog只支持`STATEMENT`这种格式！而这种格式在读已提交(Read Commited)这个隔离级别下主从复制是有bug的，因此Mysql将可重复读(Repeatable Read)作为默认的隔离级别**

4. 可重复读是如何避免不可重复读的

   用到了**MVCC**多版本并发控制，这样就保证了事务能够查询到被修改之前的数据值。它会给每一行默认加上创建事务版本号和删除事务版本号，于是乎，默认的隔离级别（REPEATABLE READ）下，增删查改变成了这样：

   - SELECT
     - 读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的。
   - INSERT
     - 将当前事务的版本号保存至行的创建版本号
   - UPDATE
     - **新插入一行**，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号
   - DELETE
     - 将当前事务的版本号保存至行的删除版本号

   **利用MVCC实现一致性非锁定读，这就有保证在同一个事务中多次读取相同的数据返回的结果是一样的，解决了不可重复读的问题**

   [consistent read](https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_consistent_read) （一致性读），InnoDB用多版本来提供查询数据库在某个时间点的快照。如果隔离级别是REPEATABLE READ，那么在同一个事务中的所有一致性读都读的是事务中第一个这样的读读到的快照；如果是READ COMMITTED，那么一个事务中的每一个一致性读都会读到它自己刷新的快照版本。Consistent read（一致性读）是READ COMMITTED和REPEATABLE READ隔离级别下普通SELECT语句默认的模式。一致性读不会给它所访问的表加任何形式的锁，因此其它事务可以同时并发的修改它们。

   **利用Gap Locks和Next-Key可以阻止其它事务在锁定区间内插入数据，因此解决了幻读问题**

   - Record Locks（记录锁）：在索引记录上加锁。
   - Gap Locks（间隙锁）：在索引记录之间加锁，或者在第一个索引记录之前加锁，或者在最后一个索引记录之后加锁。
   - Next-Key Locks：在索引记录上加锁，并且在索引记录之前的间隙加锁。它相当于是Record Locks与Gap Locks的一个结合。

   **整理：**

   Innodb通过MVCC多版本并发控制，通过版本链，实现一个数据的多个版本，然后readview实现不同生成策略来实现不同的隔离级别。MVCC实现了一致性非锁定读，也就是如果隔离级别是可重复读，那么这个事务中的查询操作都以第一个这样的读快照为准，那如果是已提交读的话就是以刷新过后的快照版本为准。

   而解决幻读主要依靠临界锁，也就是根据查询的索引，如果是唯一约束的索引，那么临界锁就会退化到记录锁，如果是普通索引没有唯一约束，那么临界锁会锁住查询索引以及前后区间，防止其他事物插入数据出现幻读。

5. mysql支持的引擎模式

   - **innodb**(mysql 默认)

     InnoDB给MySQL的表提供了事务处理、回滚、崩溃修复能力和多版本并发控制的事务安全。在MySQL从3.23.34a开始包含InnnoDB。它是MySQL上第一个提供外键约束的表引擎。而且InnoDB对事务处理的能力，也是其他存储引擎不能比拟的

6. innodb特点

   - ​    **支持事务**(事务是指逻辑上的一组操作,组成这组操作的各个单元,要么全成功,要么全失败)
   - ​    **行级锁定**(更新时一般是锁定当前行):通过索引实现,全表扫描仍然会是锁定整个表,注意间隙锁的影响.
   - ​    读写阻塞与事务隔离级别相关.
   - ​    InnoDB存储引擎总支持AUTO_INCREMENT，并且自增长的列必须是主键
   - ​    具有非常高效的**缓存特性**,能缓存索引,也能缓存数据.
   - ​    整个表和主键以Cluster方式存储,组成一颗平衡树.
   - ​    所有Secondary Index 都会保存主键信息.
   - ​    支持分区,表空间.类似于Oracle数据库.
   - ​    支持外键约束,不支持全文索引,5.5之前支持,后面不再支持.
   - ​    和MyISAM相比,InnoDB对于硬件资源要求比较高.

7. innodb下一条update执行过程

   https://time.geekbang.org/column/article/68633

8. innodb 怎么实现事务

   事务就是逻辑上一整套操作，必须全部完成，并且所做的修改永久保存，ACID

   事务的持久性、原子性、一致性通过redo/undo log 实现

   重做日志用来实现事务的**持久性**，由以下两部分组成：

   重做日志缓冲区（redo log buffer），内存中，易丢失。
   重做日志文件（redo log file），磁盘中，持久的。
   redo log buffer 是顺序写入的，在数据库运行时不需要进行读取，只会在数据库启动的时候读取来进行数据的恢复工作。
   redo log file 是物理日志，所谓的物理日志是指日志中的内容都是直接操作物理页的命令，重做时是对某个物理页进行相应的操作。

   有内存和磁盘上的两个对应实体，我们就知道这样做一定是为了效率考虑，因为内存的读写效率要比磁盘读写效率高太多。

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190924170910578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1emhvbmdtaW4wNQ==,size_16,color_FFFFFF,t_70)

   1. 先将原始数据从磁盘中读入到内存中，修改数据的内存拷贝；
   2. 生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值；
   3. 必要的时候，采用追加写的方式将 redo log buffer 中的内容刷新到 redo log file；
   4. 定期将内存中修改的数据刷新到磁盘中(这里有个**刷盘策略**)

9. 数据库索引类别

   - 哈希表

     等值查询很棒，区间查询不行

   - 有序数组

     等值查询和区间查询都很棒

     插入不行，只适合静态数据

   - b+树

     在innodb中，主键索引也叫作聚簇索引，非主键索引也叫作二级索引

     主键索引：叶子节点储存整行的值

     非主键索引：叶子节点=键值+书签，这个书签在innodb中表示主键

     非主键索引查询的时候需要**回表**

     **联合索引**：这个也是一种与单索引相对的索引如(id,name)，作为一个索引，这个索引在B+树中的结构是非叶子节点里面储存了储存了好几个值，但是在兄弟节点的比较中是按照索引从左往右顺序比大小的。

10. 维护、优化索引

   因为B+树在插入的时候就涉及到节点分裂和页分裂，以及他们的合并过程

   可以通过explain +sql语句查看执行计划

   ![img](https://images2017.cnblogs.com/blog/1254583/201710/1254583-20171013185936121-1128681571.png)

   type=all表示进行了全表扫描，extra是NULL表示没有使用索引，extra是Using index condition时候表示使用了二级索引，那就意味着需要回表

   还可以查看运行时间

   1. 自增主键。这样主键索引只需要在后面顺序插入就可以
   2. 覆盖索引，可以优化，但是注意不要返回太多的值，像select *

11. index ----普通的索引,数据可以重复

    fulltext----全文索引，用来对大表的文本域(char，varchar，text)进行索引。语法和普通索引一样。 

    unique ----唯一索引,唯一索引,要求所有记录都唯一

    primary key ----主键索引,也就是在唯一索引的基础上相应的列必须为主键

12. 索引覆盖（都是说非聚簇索引）

   select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。

11. 索引下推（针对联合索引）

    **减少回表次数** 在回表的时候先在索引树内部进行判断，时候这个索引对成立，然后再去决定回不回表。因为联合索引是默认左边最先匹配

12. 千万级大表优化

    - 首先从规范设计来入手，就是表的结构设计
    - 优化sql、索引
    - 加缓存（读多写少）

