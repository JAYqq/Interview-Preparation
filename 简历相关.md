主要做两个平台，一个是web端，提供了一个可以标注国画的平台，一个android端，可以上传国画图片然后返回检测报告。我主要做的是web端和训练国画模型的工作。前期是直接用了sift提取全图特征，然后发现相似度不高，然后改用先划分局部特征区域然后分别提取特征值之后做聚类

## SIFT

https://blog.csdn.net/dcrmg/article/details/52577555

主要就是通过构建不同尺度下的图像，也就是DOG金字塔，然后对金字塔的每一组进行极值点的检测之后，对这些不同尺度的图像进行归一化，后面得出的查分图像蕴含的特征就是我们的特征。

高斯金字塔---》上下两层相减得到差分高斯金字塔---》计算局部最大值（周围3*3以及上下两层）

1. 构建DOG金字塔

   每一组都是由尺度相同的图像组成，每组之间尺度不同

   ![img](https://img-blog.csdn.net/20160917223500317)

## **selectivesearch**

1. 区域合并

   首先通过[基于图的图像分割方法](https://blog.csdn.net/guoyunfei20/article/details/78727972)初始化原始区域，就是将图像分割成很多很多的小块。然后我们使用贪心策略，计算每两个相邻的区域的相似度，然后每次合并最相似的两块，直到最终只剩下一块完整的图片。然后这其中每次产生的图像块包括合并的图像块我们都保存下来。

2. 怎么计算相似度的呢

   主要参考了三种多样性策略

   - 多种颜色空间，考虑RGB、灰度等
   - 多种相似度度量标准，既考虑颜色相似度，又考虑纹理、大小、重叠情况等。
   - 通过改变阈值初始化原始区域，阈值越大，分割的区域越少。

   把单一的相似归一化到[0,1]之间



## elasticsearch

elasticsearch设计的理念就是分布式搜索引擎，底层实现还是基于Lucene的，这个Lucene是一个文档性数据库，核心思想是在多态机器上启动多个es进程实例，组成一个es集群。一个集群里面有多个节点，每个节点就是一台单一的服务器，用来存储数据，并且参与集群和搜索功能，一个节点可以通过配置特定的名称来加入特定的集群。正是这样的集群模式，在进行查询的时候，是根据token去找到对应的索引，这边是用了倒排索引的方式，也就是将词条作为key去对应到这个key出现在哪些文档中。但是为了快速确定这个token对应哪个term，ES就直接把所有term排了序，然后二分查找。但是所有储存的term会很大，直接放到内存中就会爆炸，所以ES这边用了**Term Index**，像是B树一样减少查询磁盘的次数。它仅仅取了term的前缀，像字典树，这样就可以通过term index找到term字典中对应的数据了。

#### 倒排索引

像窗前明月光，床、明月都建立索引，

## **RQ队列**

RQ最重要的几个概念是

- Exchange：消息交换机,它指定消息按什么规则,路由到哪个队列。
- Queue:消息的载体,每个消息都会被投到一个或多个队列。
- Routing Key:路由关键字,exchange根据这个关键字进行消息投递。
- vhost:虚拟主机,一个broker里可以有多个vhost，用作不同用户的权限分离。
- Producer:消息生产者,就是投递消息的程序.
- Consumer:消息消费者,就是接受消息的程序.



## Docker

https://zhuanlan.zhihu.com/p/138837121

https://zhuanlan.zhihu.com/p/52938416

1. **镜像** 我们开机的时候，linux内核会先启动，然后挂载root文件系统作为用户空间；而Docker镜像就相当于是一个根文件系统，但是如果在实际开发中如果需要每做一些改变，也需要手动同步改变，就违背了docker的初衷。所以docker是分层创建，每一层是静态的，可以持久储存的。**删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除**。新构建一层都会创建指针指向前一层。docker使用**统一文件系统**同将这么多层的文件整合成一个文件系统，为应用层提供了一个统一的视角，看起来就像只有一个文件。

2. **容器** **容器是一个应用层抽象，运行在操作系统之上的**。

   容器其实是在对应的镜像上加上了一层读写层。容器和虚拟机的不同在于虚拟机是虚拟化了计算机的所有硬件，去模拟硬件IO，所以可以说每一个虚拟机有一个内核。而docker是在内核之上，多个容器共享一个kernel，所以可以直接使用系统提供的接口。

3. 环境隔离

   docker是怎么做到环境的隔离，答案就是 **Namespace**

   namespace是为了隔离进程，让进程之间彼此不可见。做法就是每个容器是一个进程实例，然后这个进程属于自己的namespace，Linux上的做法也就是在创建进程的时候携带一个参数告诉系统需要一个namespace而已，在用户看来每一个容器有自己的初始进程，也就是进程号为1，然后在容器里面创建进程，进程号就会依次增大。

   docker的namespace是基于Linux系统的namespace的集合，包括Pid namespace，Cpu namespace等等

   但是这样只做到了环境的隔离，但是其实对一些资源的操作仍然是全局的，比如内存、CPU等，如果不做资源的隔离，容器彼此之间还是会有影响。

   在容器开启以后，可以在/proc/<pid>

4. 资源限制 **cGroup**

   cgroup用来限定一个进程的资源使用，是指一些硬件的资源，比如CPU，内存，磁盘等。这个cgroup在linux中的/sys目录下也有，该目录下有很多子系统，像内存，CPU。Cgroup主要通过：

   - 子系统

     也就是一个资源管理器，用来做资源的分配管理，面向的都是控制组。比如我们在/sys/cgroups/cpu下创建一个文件夹，然后系统就会自动在文件夹下创建一些文件，可以将进程ID放到tasks文件中，然后在其他配置文件中对这个进程进行CPU的时间分配，这样就可以实现对一个进程的资源管理，这个文件夹就是cpu资源的一个控制组。docker其实就是对这些操作进行了自动化资源分配。

   - 控制组

     一个控制组包含了多个进程，每个进程都受这个控制组的资源规则的管理

   - 层级

     一个子系统下的控制组通过树形结构连接，子节点继承父节点的规则。

5. 统一文件系统

   最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下

6. 所以docker是通过namespace和cgroup进行环境隔离和资源隔离的





## 消息队列

消息队列在业务上主要的功能有：

1. 解耦

   生产者不需要将任务放在自己这里处理，而是只需要集中放到一个地方处理任务，消费者只需要去这个地方自己去拿就可以

2. 异步

   如果每一个任务都需要生产者这边把所有的逻辑处理完，这样就造成阻塞

3. 削峰

   在大量请求在同一时间出现的时候，可以暂时将这些请求放在消息队列做缓冲

消息队列的主要模式：

1. 点对点模式

   **特点**：就是一个消息只会被一个消费者处理，生产者将消息放到队列，生产者自己拿。

   **优点**：消费者有主动权去取消息

   **缺点**：消费者无法感知消息的存在

2. 发布订阅模式

   **特点**：生产者将消息放到队列中后，队列会主动将消息推送给订阅了该消息的消费者，所以消费者不需要感知消息的存在

   **优点**：主动推送服务

   **缺点**：由于是主动过推送数据，所以推送速度是一个问题，因为队列不清楚消费者的处理速度。

## Kafka

Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力

那么，到底卡夫卡强在哪里？

先放图

![](https://pic1.zhimg.com/80/v2-4692429e9184ed4a93911fa3a1361d28_1440w.jpg)

### 基本术语

- Producer  生产者
- cluster     集群，集群中的基本单位是broker，集群的存在也是为了高可用
- broker     集群中每个broker都有一个唯一的ID，并且一个broker包含多个kafka实例，通常一个broker是一台服务器
- topic       主题，业务上的理解，比如是订单主题，那么就是Order，实现了不同业务需要的分离
- partition    分区。一个主题有多个分区，用来提高吞吐率。因为单个分区可能会造成数据过大，所以分区可以让数据被分割开来。但是每个分区的leader都是放在不同的broker
- Replication    每个分区有不同的副本，是为了高可用。同一个分区在一个broker中只会存在一个副本，并且leader副本和追随者副本一定在不同的机器上，因为副本的存在就是为了防止一个broker宕机后失效。
- Consumer     消费者
- Consumer Group      消费者组，后面展开

### 关于消费者组

首先，kafka中消费者组下的实例，我们可以理解为一个个的线程或者进程，它们去订阅的topic的分区中读取信息。每个消费者组都有一个Group ID，是一个字符串唯一标示。

另外一个消费者组中同时只能有一个消费者去消费同一个分区，但是组内的消费者可以去消费不同的分区。在这边的处理其实是点对点模式。如果这边是可以多个消费者去消费，当然也可以，但是会出现重复消费，因为消费者需要从消费组拿消费位移去分区消费，所以多个一起就是拿着相同的位移量。

所以说

### kafka如何保证高可用？

1. 集群。多个broker组成一个集群，这样保证了一个broker宕机后，可以有其他的broker继续运行

2. 副本机制。如果一个主题只存在一份数据，那么这个主题存在的broker宕机后也就消失了，所以存在副本对一个主题保留多份，这样可以保证数据的不丢失。**副本分为leader副本和follower副本**，leader对外提供服务而follower副本只是向leader发起请求，保证与leader的数据一致性

3. 分区机制。因为如果一个主题只是在一份数据保存，那么这个数据的伸缩性就出现了问题，所以对一个主题的数据进行分区，每个分区的数据顺序写入分区中。

4. 分区再均衡

   后面展开

### 分区再均衡

当一个消费者组里面的某个工作状态的消费者挂了，那么消费者组中其他的活着的消费者就会顶替过来，这种机制也叫做 **重平衡**。

### Leader选举

如果leader分区挂掉了，那么就需要一个新的leader，那么这些新的leader是从ISR列表中选举出来，某一 follower 副本中的消息比 leader 延时超过10s，就会被从 ISR 中排除，这么做也是为了尽量保证数据的一致性。

如果ISR中是空的，那么就是**Unclean leader 选举**，这是一个可控参数，开启后可以使得一个非同步的副本参与leader选举，但是这样做会破坏数据的一致性，所以不建议这么做，因为往往在开发中数据的一致性会比可用性更重要。

### 位移

**区内位移**

也就是每个消息在它所在的分区的位置

**消费者位移**

每个消费者需要记录自己消费到了哪个位置，储存在消费者端

### 关于读写分离

kafka是不支持像mysql的读写分离的，所有的读写操作都是到leader副本处理的，follower副本主要负责拉取leader的更新，进行数据同步。

虽然所有的读写请求都打在leader上，但是因为kafka中每个topic都进行了分区处理，所以相当于做了一层负载，所以读写分离不需要了。另外由于副本的同步是异步的，从 follower 副本读取数据可能会读不到最新的消息，所以可能会存在数据不一致的问题。



### kafka常用命令

1. 创建topic

   ```shell
   kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <topic name>
   ```

2. 产生消息

   ```shell
   kafka-console-producer --broker-list localhost:9092 --topic <topic name>
   ```

3. 消费

   ```shell
   kafka-console-consumer --bootstrap-server localhost:9092 --topic <topic name> --from-beginning
   ```

   如果是消费组

   ```shell
   kafka-console-consumer --bootstrap-server localhost:9092 --topic <topic name> --group test-consumer1 --from-beginning
   ```

4. 查看topic list

   ```shell
   kafka-topics --list --zookeeper localhost:2181
   ```

5. 

docker run --name kafka \
-p 9092:9092 \
-e KAFKA_BROKER_ID=0 \
-e KAFKA_ZOOKEEPER_CONNECT=127.0.0.1:2181 \
-e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092 \
-e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \
 -d wurstmeister/kafka  



